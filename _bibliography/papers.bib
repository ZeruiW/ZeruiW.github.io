---
---


@article{10020313,
  author={Huang*, Jun and Wang*, Zerui and Li, Ding and Liu, Yan},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={The Analysis and Development of an XAI Process on Feature Contribution Explanation}, 
  year={2022},
  volume={},
  number={},
  pages={5039-5048},
  keywords={Measurement;Analytical models;Codes;Systematics;Taxonomy;Big Data;Data models;Explainable AI;Feature Importance;XAI Process;Machine Learning;Deep Learning},
  doi={10.1109/BigData55660.2022.10020313},
  abbr={IEEE BigData 22},
  bibtex_show={true},
  html={https://ieeexplore.ieee.org/document/10020313},
  preview={xaiprocess.gif},
  pdf={xaiprocess.pdf},
  selected={true},
  abstract={Explainable Artificial Intelligence (XAI) research focuses on effective explanation techniques to understand and build AI models with trust, reliability, safety, and fairness. Feature importance explanation summarizes feature contributions for end-users to make model decisions. However, XAI methods may produce varied summaries that lead to further analysis to evaluate the consistency across multiple XAI methods on the same model and data set. This paper defines metrics to measure the consistency of feature contribution explanation summaries under feature importance order and saliency map. Driven by these consistency metrics, we develop an XAI process oriented on the XAI criterion of feature importance, which performs a systematical selection of XAI techniques and evaluation of explanation consistency. We demonstrate the process development involving twelve XAI methods on three topics, including a search ranking system, code vulnerability detection and image classification. Our contribution is a practical and systematic process with defined consistency metrics to produce rigorous feature contribution explanations.}
  }


@article{Wang2024,
  abbr={IEEE TCC},
  bibtex_show={true},
  author={Wang, Zerui and Liu, Yan and Huang, Jun},
  journal={IEEE Transactions on Cloud Computing}, 
  title={An Open API Architecture to Discover the Trustworthy Explanation of Cloud AI Services}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  keywords={Artificial intelligence;Cloud computing;Computer architecture;Computational modeling;Data models;Measurement;Microservice architectures;Cloud model service;microservices;software architecture;software quality;explainable AI},
  doi={10.1109/TCC.2024.3398609},
  html={https://ieeexplore.ieee.org/document/10529172},
  preview={XAIarchitecture.gif},
  pdf={An_Open_API_Architecture.pdf},
  abstract={This paper presents the design of an open-API-based explainable AI (XAI) service to provide feature contribution explanations for cloud AI services. Cloud AI services are widely used to develop domain-specific applications with precise learning metrics. However, the underlying cloud AI services remain opaque on how the model produces the prediction. We argue that XAI operations are accessible as open APIs to enable the consolidation of the XAI operations into the cloud AI services assessment. We propose a design using a microservice architecture that offers feature contribution explanations for cloud AI services without unfolding the network structure of the cloud models. We can also utilize this architecture to evaluate the model performance and XAI consistency metrics showing cloud AI services' trustworthiness. We collect provenance data from operational pipelines to enable reproducibility within the XAI service. Furthermore, we present the discovery scenarios for the experimental tests regarding model performance and XAI consistency metrics for the leading cloud vision AI services. The results confirm that the architecture, based on open APIs, is cloud-agnostic. Additionally, data augmentations result in measurable improvements in XAI consistency metrics for cloud AI services.},
  selected={true}
}

@article{Wang2024Poster,
  abbr={CANAI},
  journal={The 36th Canadian Conference on Artificial Intelligence}, 
  title={Poster: Design Explanation Microservices and Provenance: A Case Study of Explaining Cloud AI Service}, 
  year={2023},
  keywords={Artificial intelligence;Cloud computing;Computer architecture;Computational modeling;Data models;Measurement;Microservice architectures;Cloud model service;microservices;software architecture;software quality;explainable AI},
  preview={posterxai.gif},
  pdf={PosterXAIservice.pdf},
}


@article{wang2024xaiport,
  abbr={ICSE 24},
  bibtex_show={true},
  title={XAIport: A service framework for the early adoption of xai in ai model development},
  author={Wang, Zerui and Liu, Yan and Thiruselvi, Abishek Arumugam and Hamou-Lhadj, Abdelwahab},
  journal={arXiv preprint arXiv:2403.16858},
  year={2024},
  doi={10.1145/3639476.3639759},
  html={https://conf.researchr.org/details/icse-2024/icse-2024-new-ideas-and-emerging-results/3/XAIport-A-Service-Framework-for-the-Early-Adoption-of-XAI-in-AI-Model-Development},
  preview={ICSE_2024.gif},
  pdf={ICSE_2024.pdf},
  abstract={In this study, we propose the early adoption of Explainable AI (XAI) with a focus on three properties: 
Quality of explanation, the explanation summaries should be consistent across multiple XAI methods; 
Architectural Compatibility, for effective integration in XAI, the architecture styles of both the XAI methods and the models to be explained must be compatible with the framework;
Configurable operations, XAI explanations are operable, akin to machine learning operations. 
Thus, an explanation for AI models should be reproducible and tractable to be trustworthy. 
We present XAIport, a framework of XAI microservices encapsulated into Open APIs to deliver early explanations as observation for learning model quality assurance. 
XAIport enables configurable XAI operations along with machine learning development. 
We quantify the operational costs of incorporating XAI with three cloud computer vision services on Microsoft Azure Cognitive Services, Google Cloud Vertex AI, and Amazon Rekognition. 
Our findings show comparable operational costs between XAI and traditional machine learning, with XAIport significantly improving both cloud AI model performance and explanation stability.},
  selected={true}
}

@article{wang2024cloud,
  abbr={IEEE SSE 24},
  bibtex_show={true},
  title={Cloud-based XAI Services for Assessing Open Repository Models Under Adversarial Attacks},
  author={Wang, Zerui and Liu, Yan},
  journal={arXiv preprint arXiv:2401.12261},
  year={2024},
  doi={arXiv:2401.12261},
  html={https://github.com/ZeruiW/XAIport},
  preview={IEEESSE.gif},
  pdf={IEEE_SSE.pdf},
  abstract={The opacity of AI models necessitates both validation and evaluation before their integration into services. To investigate these models, explainable AI (XAI) employs methods that elucidate the relationship between input features and output predictions. The operations of XAI extend beyond the execution of a single algorithm, involving a series of activities that include preprocessing data, adjusting XAI to align with model parameters, invoking the model to generate predictions, and summarizing the XAI results. Adversarial attacks are well-known threats that aim to mislead AI models. The assessment complexity, especially for XAI, increases when open-source AI models are subject to adversarial attacks, due to various combinations. To automate the numerous entities and tasks involved in XAI-based assessments, we propose a cloud-based service framework that encapsulates computing components as microservices and organizes assessment tasks into pipelines. The current XAI tools are not inherently service-oriented. This framework also integrates open XAI tool libraries as part of the pipeline composition. We demonstrate the application of XAI services for assessing five quality attributes of AI models: (1) computational cost, (2) performance, (3) robustness, (4) explanation deviation, and (5) explanation resilience across computer vision and tabular cases. 
The service framework generates aggregated analysis that showcases the quality attributes for more than a hundred combination scenarios.},
  selected={true}
}

@article{wang2024cloudposter,
  abbr={SEMLA},
  title={Poster: Cloud-based XAI Services for Assessing AI Models Under Adversarial Attacks},
  journal={Software Engineering for Machine Learning Applications (SEMLA) international symposium},
  year={2024},
  preview={PosterSSE.gif},
  pdf={posterSSE.pdf},
  selected={False}
}

@ARTICLE{10098190,
  author={Li, Ding and Liu, Yan and Huang, Jun and Wang, Zerui},
  journal={Computer}, 
  title={A Trustworthy View on Explainable Artificial Intelligence Method Evaluation}, 
  year={2023},
  volume={56},
  number={4},
  pages={50-60},
  keywords={Measurement;Artificial intelligence},
  doi={10.1109/MC.2022.3233806},
  abbr={IEEE Computer},
  bibtex_show={true},
  html={https://ieeexplore.ieee.org/document/10098190},
  preview={A_Trustworthy_View_on_Explainable.gif},
  pdf={A_Trustworthy_View_on_Explainable.pdf},
  abstract={In this article, we follow a process of explainable artificial intelligence (XAI) method development and define two metrics in terms of consistency and efficiency in guiding the evaluation of XAI explanations.}
}

@INPROCEEDINGS{10197114,
  author={Neghawi, Elie and Wang, Zerui and Huang, Jun and Liu, Yan},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Linking Team-level and Organization-level Governance in Machine Learning Operations through Explainable AI and Responsible AI Connector}, 
  year={2023},
  volume={},
  number={},
  pages={1223-1230},
  keywords={Industries;Ethics;Software design;Navigation;Software algorithms;Microservice architectures;Organizations;AI;AI ethics;trustworthy AI;XAI;AIMLOps;AIOps;software engineering;software architecture;pattern;best practice},
  doi={10.1109/COMPSAC57700.2023.00185},
  abbr={COMPSAC 23},
  bibtex_show={true},
  html={https://ieeexplore.ieee.org/document/10197114},
  preview={Linking_Team.gif},
  pdf={Linking_Team.pdf},
  abstract={This paper presents the design of an open-API-based explainable AI (XAI) service to provide feature contribution explanations for cloud AI services. Cloud AI services are widely used to develop domain-specific applications with precise learning metrics. However, the underlying cloud AI services remain opaque on how the model produces the prediction. We argue that XAI operations are accessible as open APIs to enable the consolidation of the XAI operations into the cloud AI services assessment. We propose a design using a microservice architecture that offers feature contribution explanations for cloud AI services without unfolding the network structure of the cloud models. We can also utilize this architecture to evaluate the model performance and XAI consistency metrics showing cloud AI services' trustworthiness. We collect provenance data from operational pipelines to enable reproducibility within the XAI service. Furthermore, we present the discovery scenarios for the experimental tests regarding model performance and XAI consistency metrics for the leading cloud vision AI services. The results confirm that the architecture, based on open APIs, is cloud-agnostic. Additionally, data augmentations result in measurable improvements in XAI consistency metrics for cloud AI services.}  
  }
